{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Camemmbert_foods.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"712adec253ef4a19a899a0856b60da17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_40fd2a681818466aa2812438225e6d78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1cc09a9dae804e76b09f3361ea59fc6b","IPY_MODEL_4b654b364c2447d797dec1bcdc6fcfb9"]}},"40fd2a681818466aa2812438225e6d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cc09a9dae804e76b09f3361ea59fc6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c45b711935e34a89aaf22b9a4efde4a2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":810912,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":810912,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09baf624cd74461ebd268b142af907cd"}},"4b654b364c2447d797dec1bcdc6fcfb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1bf467797bfc49f399acb3241aee41c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 811k/811k [00:00&lt;00:00, 1.48MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3298efc1937440849ad3364179c390eb"}},"c45b711935e34a89aaf22b9a4efde4a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09baf624cd74461ebd268b142af907cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bf467797bfc49f399acb3241aee41c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3298efc1937440849ad3364179c390eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6551ee5ed64241869c6a0cd915054a26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9f39f53491f449439b6a108251066dd7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a891574519f44ba08e323a6c6ab71d4c","IPY_MODEL_8fc89a4e74b844d9919d972626c795fc"]}},"9f39f53491f449439b6a108251066dd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a891574519f44ba08e323a6c6ab71d4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fc7d76729e2747bcb159a6f68abc74a6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_66f16324cf9d4a8094c2673ae062ac93"}},"8fc89a4e74b844d9919d972626c795fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_524e86b81ed94da5b3e88500af36a817","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 508/508 [00:20&lt;00:00, 24.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d96580f66f347e591da41d384514ef4"}},"fc7d76729e2747bcb159a6f68abc74a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"66f16324cf9d4a8094c2673ae062ac93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"524e86b81ed94da5b3e88500af36a817":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d96580f66f347e591da41d384514ef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0bcce4379bd46cf94acae9f8de0ee3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0f42a1f4f8be4262a2dc48894ce7e48a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1ab83a1282054b0eb75646732d2f3402","IPY_MODEL_1e5ff8fa9c5e407ab21fceacbeb1cfb1"]}},"0f42a1f4f8be4262a2dc48894ce7e48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ab83a1282054b0eb75646732d2f3402":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9040afb2e2244673bc1ea283b014b365","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":445032417,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":445032417,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbbc9de72f564dbcbd63f8150ee34bb7"}},"1e5ff8fa9c5e407ab21fceacbeb1cfb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41aae41158344bfc857811bd33e00e0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 445M/445M [00:06&lt;00:00, 67.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1261cbb3da584b49ad1297313404bf68"}},"9040afb2e2244673bc1ea283b014b365":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dbbc9de72f564dbcbd63f8150ee34bb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41aae41158344bfc857811bd33e00e0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1261cbb3da584b49ad1297313404bf68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"O0Vnur_hxGAI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1598042938426,"user_tz":-60,"elapsed":10527,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"894b3057-479e-4894-ee37-c8d00d96a114"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 8.7MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 24.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 44.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 52.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=39e5d49b0b87dbad971af841da909a866ba02a88ca7bc92011941c522cb8d768\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zw8lAlBfxam-","colab_type":"code","colab":{}},"source":["import io\n","import torch\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tqdm import tqdm, trange\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import AdamW, CamembertForSequenceClassification\n","from transformers import CamembertTokenizer, CamembertConfig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuPfRZy5xkc9","colab_type":"code","colab":{}},"source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3HWr-ChxwB-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598043037755,"user_tz":-60,"elapsed":16001,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"19762e49-4e28-4836-f5cd-ee17561e4a8e"},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"7lfNwPIkyWFR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1598043071134,"user_tz":-60,"elapsed":25160,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"62da9f4e-da67-49a4-81c1-58e390bbadcd"},"source":["from google.colab import drive\n","drive.mount('/gdrive/')\n","%cd /gdrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive/\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3QSZsrqUyb_2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1598043164358,"user_tz":-60,"elapsed":2718,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"59fe8a4a-ff27-4148-b8bd-def28acee4db"},"source":["import pandas as pd\n","df = pd.read_csv('My Drive/Colab_Notebooks/selected_foods.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>i love this water it does not taste good unles...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>we have been looking for pesto that tastes as ...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i make own sausages back in ireland and this i...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>anything that says enriched in the ingredients...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>amazon normally does a fantastic job getting p...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  i love this water it does not taste good unles...      4\n","1  we have been looking for pesto that tastes as ...      4\n","2  i make own sausages back in ireland and this i...      4\n","3  anything that says enriched in the ingredients...      1\n","4  amazon normally does a fantastic job getting p...      2"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"0qvY35yhy4PR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598043276293,"user_tz":-60,"elapsed":856,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"cdc2616c-85ec-4fbd-acc2-6fadea79416f"},"source":["df.label = df.label-1\n","np.unique(df.label)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"sLYlAgZqzUBT","colab_type":"code","colab":{}},"source":["max_length = 80\n","learning_rate = 2e-5\n","batch_size = 64\n","epochs = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rA3HTlNpzZIj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["712adec253ef4a19a899a0856b60da17","40fd2a681818466aa2812438225e6d78","1cc09a9dae804e76b09f3361ea59fc6b","4b654b364c2447d797dec1bcdc6fcfb9","c45b711935e34a89aaf22b9a4efde4a2","09baf624cd74461ebd268b142af907cd","1bf467797bfc49f399acb3241aee41c5","3298efc1937440849ad3364179c390eb","6551ee5ed64241869c6a0cd915054a26","9f39f53491f449439b6a108251066dd7","a891574519f44ba08e323a6c6ab71d4c","8fc89a4e74b844d9919d972626c795fc","fc7d76729e2747bcb159a6f68abc74a6","66f16324cf9d4a8094c2673ae062ac93","524e86b81ed94da5b3e88500af36a817","7d96580f66f347e591da41d384514ef4","a0bcce4379bd46cf94acae9f8de0ee3a","0f42a1f4f8be4262a2dc48894ce7e48a","1ab83a1282054b0eb75646732d2f3402","1e5ff8fa9c5e407ab21fceacbeb1cfb1","9040afb2e2244673bc1ea283b014b365","dbbc9de72f564dbcbd63f8150ee34bb7","41aae41158344bfc857811bd33e00e0d","1261cbb3da584b49ad1297313404bf68"]},"executionInfo":{"status":"ok","timestamp":1598043354684,"user_tz":-60,"elapsed":42250,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"61094e8d-b9c3-4eda-bea0-1a0ef7eafdfb"},"source":["# Create sentence and label lists\n","initial_sentences = df.sentence.values\n","initial_labels = df.label.values\n","\n","tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in initial_sentences]\n","# print (\"Tokenize the first sentence:\")\n","# print (tokenized_texts[0])\n","\n","index = []\n","for i,x in enumerate(tokenized_texts):\n","    if len(x)<max_length:\n","        index.append(i)\n","sentences = []\n","labels=[]\n","for i in index:\n","   sentences.append(initial_sentences[i]) \n","   labels.append(initial_labels[i])\n","\n","\n","tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)\n","tokenized_texts = [[\"[CLS] \"] + tokenizer.tokenize(sent) + [\" [SEP]\"] for sent in sentences]\n","# print (\"Tokenize the first sentence:\")\n","# print (tokenized_texts[0])\n","\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","# Use train_test_split to split our data into train and validation sets for training\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=2018, test_size=0.1)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=2018, test_size=0.1)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=5)\n","model.cuda()\n","\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","\n","# This variable contains all of the hyperparemeter information our training loop needs\n","optimizer = AdamW(optimizer_grouped_parameters,\n","                     lr=learning_rate,\n","                     )\n","\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"712adec253ef4a19a899a0856b60da17","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=810912.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6551ee5ed64241869c6a0cd915054a26","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0bcce4379bd46cf94acae9f8de0ee3a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445032417.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z75D72JOzdDo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1598044382505,"user_tz":-60,"elapsed":526,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"530ec4a4-09d7-4a2d-9051-53de4cd7307e"},"source":["# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","  # Training\n","  model.train()\n","  \n","  # Tracking variables\n","  training_loss = 0\n","  nbatch_training_examples, nbatch_training_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    batch_input_ids, batch_input_mask, batch_labels = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    loss = model(batch_input_ids,  attention_mask=batch_input_mask, labels=batch_labels)\n","\n","    train_loss_set.append(loss[0])    \n","    # # Backward pass\n","    loss[0].backward()\n","    optimizer.step()\n","     \n","    \n","    # Update tracking variables\n","    training_loss =training_loss+ loss[0]\n","    nbatch_training_examples =nbatch_training_examples+ batch_input_ids.size(0)\n","    nbatch_training_steps =nbatch_training_steps+ 1\n","\n","  print(\"Train loss: {}\".format(training_loss/nbatch_training_steps))\n","    \n","    \n","  # Validation\n","  model.eval()\n","\n","  # Tracking variables \n","  evaluation_loss, evaluation_accuracy = 0, 0\n","  nbatch_evaluation_steps, nbatch_evaluation_examples = 0, 0\n","  eval_f1, eval_precision = 0,0\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    batch_input_ids, batch_input_mask, batch_labels = batch\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      logits = model(batch_input_ids,  attention_mask=batch_input_mask)[0]\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = batch_labels.to('cpu').numpy()\n","\n","    tmp_evaluation_accuracy = accuracy_score(np.argmax(logits, axis=1).flatten(), label_ids.flatten()) \n","    eval_f1 += f1_score(np.argmax(logits, axis=1).flatten(), label_ids.flatten(), average='weighted') \n","    eval_precision += precision_score(np.argmax(logits, axis=1).flatten(), label_ids.flatten(), average='weighted')\n","    \n","    evaluation_accuracy = evaluation_accuracy + tmp_evaluation_accuracy\n","    nbatch_evaluation_steps = nbatch_evaluation_steps+1\n","\n","  print(\"Validation Accuracy: {}\".format(evaluation_accuracy/nbatch_evaluation_steps))\n","  print(\"Validation F1 score: {}\".format(eval_f1/nbatch_evaluation_steps))\n","  print(\"Validation precision: {}\".format(eval_precision/nbatch_evaluation_steps))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 1.3847728967666626\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  25%|██▌       | 1/4 [03:55<11:45, 235.17s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.5045854732208364\n","Validation F1 score: 0.5547106732627265\n","Validation precision: 0.6717932960257689\n","Train loss: 1.0747034549713135\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 2/4 [07:51<07:51, 235.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.5643341892883346\n","Validation F1 score: 0.5791101271706001\n","Validation precision: 0.6236889648761857\n","Train loss: 0.9556152820587158\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  75%|███████▌  | 3/4 [11:48<03:55, 235.97s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.5829970652971387\n","Validation F1 score: 0.5917914981676661\n","Validation precision: 0.6250970265889767\n","Train loss: 0.8695899248123169\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 4/4 [15:45<00:00, 236.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.5883849963316214\n","Validation F1 score: 0.6076891432097059\n","Validation precision: 0.6677145698240353\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"IQRDvEorzpEU","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}