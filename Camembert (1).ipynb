{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Camembert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"77a8095aea3948b4894ed77df8ed7e9d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e2ff3c88b6443b8816b3f7a20df9efa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2176ba9fe0e34478b6e2a93b017f6a91","IPY_MODEL_852d8dfd9c384f1381b4e7ed50981925"]}},"1e2ff3c88b6443b8816b3f7a20df9efa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2176ba9fe0e34478b6e2a93b017f6a91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_727dd9093fd54a09a1515661eaf0d387","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":810912,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":810912,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17e7ba3cb3fe46029fa70084023ce396"}},"852d8dfd9c384f1381b4e7ed50981925":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f3a416eb96fb4e0a9b79986a2098558e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 811k/811k [00:01&lt;00:00, 566kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ecc267e016274feb91683269b08d833d"}},"727dd9093fd54a09a1515661eaf0d387":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"17e7ba3cb3fe46029fa70084023ce396":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3a416eb96fb4e0a9b79986a2098558e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ecc267e016274feb91683269b08d833d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebc009bb542d42f6aa79157269ba8cfe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6a23474f71549ad83a1abe41edb80c0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2bd5972ec8704035a486f7104b50df4c","IPY_MODEL_9d296190d4024579bc0b8945a99b4b2f"]}},"b6a23474f71549ad83a1abe41edb80c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2bd5972ec8704035a486f7104b50df4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_43b2a88b66ef4587b1e0f726a6c11ef2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b86f10f0f4841e4af4fbaa10fa4bfdd"}},"9d296190d4024579bc0b8945a99b4b2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3f4800edf0d64b08971f4c1597fe1e1a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 508/508 [00:01&lt;00:00, 288B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d90ce43c79548f4a327cb9aeefcfb24"}},"43b2a88b66ef4587b1e0f726a6c11ef2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b86f10f0f4841e4af4fbaa10fa4bfdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f4800edf0d64b08971f4c1597fe1e1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d90ce43c79548f4a327cb9aeefcfb24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82b6a7579d0c42668c339479343f3294":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6d630000c26142f2a03ec653616e1125","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e94a1b44672e44879385f75b913630c0","IPY_MODEL_3891508fe7ef4d0ea3711986ec177ba5"]}},"6d630000c26142f2a03ec653616e1125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e94a1b44672e44879385f75b913630c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_24abc8f92287458abfeb015eceb04dc5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":445032417,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":445032417,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2b554825c974bd08aac1c43c44a457d"}},"3891508fe7ef4d0ea3711986ec177ba5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee204875f94c43b1b36eca1988c04827","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 445M/445M [00:05&lt;00:00, 74.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05c5ce76922a4faea604954b8db4e2a8"}},"24abc8f92287458abfeb015eceb04dc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a2b554825c974bd08aac1c43c44a457d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee204875f94c43b1b36eca1988c04827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05c5ce76922a4faea604954b8db4e2a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LOcY8HA9FgG_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1598048155217,"user_tz":-60,"elapsed":9586,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"ffd504e6-287c-47f3-bf71-e0e8e6992f77"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 21.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 49.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 50.3MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=7f37908d30ca299e10b622d6b2fd85b1dad3a87aa6092c0ab8d4bee1764abe4c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"__d1J85hFkyE","colab_type":"code","colab":{}},"source":["import io\n","import torch\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tqdm import tqdm, trange\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import AdamW, CamembertForSequenceClassification\n","from transformers import CamembertTokenizer, CamembertConfig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vr35SWQzF_B5","colab_type":"code","colab":{}},"source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Nt9l-2XGBzL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598048216483,"user_tz":-60,"elapsed":16694,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"ba1d72cc-2928-426c-977d-87f566a3e888"},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"mGfyu0zgGGQs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1598048306363,"user_tz":-60,"elapsed":37948,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"36b0ea86-3fa3-4fa6-bd5b-5f2e9e698d32"},"source":["from google.colab import drive\n","drive.mount('/gdrive/')\n","%cd /gdrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive/\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xxiOU4zkGXAp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1598048379251,"user_tz":-60,"elapsed":2944,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"ca389b6a-813c-4628-9f32-d55852369a2c"},"source":["import pandas as pd\n","df = pd.read_csv('My Drive/Colab_Notebooks/selected_electronics.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>i hate the thing that in the ad they say micro...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>very good product in this price range</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>great works nicely functions are smooth howeve...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>not good enough for gaming i installed blur ga...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>design and performance wise good gtx 1650 is w...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  i hate the thing that in the ad they say micro...      1\n","1              very good product in this price range      4\n","2  great works nicely functions are smooth howeve...      4\n","3  not good enough for gaming i installed blur ga...      2\n","4  design and performance wise good gtx 1650 is w...      3"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"dxeOEzK8GxWb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598048401303,"user_tz":-60,"elapsed":1357,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"88cf8ce2-94de-4ed1-a2cf-1b3aa63ccde4"},"source":["df.label = df.label-1\n","np.unique(df.label)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"KwmC2K_KG3H5","colab_type":"code","colab":{}},"source":["max_length = 40\n","learning_rate = 2e-5\n","batch_size = 64\n","epochs = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9H2-gMTBG5I2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["77a8095aea3948b4894ed77df8ed7e9d","1e2ff3c88b6443b8816b3f7a20df9efa","2176ba9fe0e34478b6e2a93b017f6a91","852d8dfd9c384f1381b4e7ed50981925","727dd9093fd54a09a1515661eaf0d387","17e7ba3cb3fe46029fa70084023ce396","f3a416eb96fb4e0a9b79986a2098558e","ecc267e016274feb91683269b08d833d","ebc009bb542d42f6aa79157269ba8cfe","b6a23474f71549ad83a1abe41edb80c0","2bd5972ec8704035a486f7104b50df4c","9d296190d4024579bc0b8945a99b4b2f","43b2a88b66ef4587b1e0f726a6c11ef2","3b86f10f0f4841e4af4fbaa10fa4bfdd","3f4800edf0d64b08971f4c1597fe1e1a","3d90ce43c79548f4a327cb9aeefcfb24","82b6a7579d0c42668c339479343f3294","6d630000c26142f2a03ec653616e1125","e94a1b44672e44879385f75b913630c0","3891508fe7ef4d0ea3711986ec177ba5","24abc8f92287458abfeb015eceb04dc5","a2b554825c974bd08aac1c43c44a457d","ee204875f94c43b1b36eca1988c04827","05c5ce76922a4faea604954b8db4e2a8"]},"executionInfo":{"status":"ok","timestamp":1598048454870,"user_tz":-60,"elapsed":34197,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"954e6d07-f7fd-47e0-a9f2-ca209638b591"},"source":["# Create sentence and label lists\n","initial_sentences = df.sentence.values\n","initial_labels = df.label.values\n","\n","tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in initial_sentences]\n","# print (\"Tokenize the first sentence:\")\n","# print (tokenized_texts[0])\n","\n","index = []\n","for i,x in enumerate(tokenized_texts):\n","    if len(x)<max_length:\n","        index.append(i)\n","sentences = []\n","labels=[]\n","for i in index:\n","   sentences.append(initial_sentences[i]) \n","   labels.append(initial_labels[i])\n","\n","\n","tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)\n","tokenized_texts = [[\"[CLS] \"] + tokenizer.tokenize(sent) + [\" [SEP]\"] for sent in sentences]\n","# print (\"Tokenize the first sentence:\")\n","# print (tokenized_texts[0])\n","\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","# Use train_test_split to split our data into train and validation sets for training\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=2018, test_size=0.1)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=2018, test_size=0.1)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=5)\n","model.cuda()\n","\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","\n","# This variable contains all of the hyperparemeter information our training loop needs\n","optimizer = AdamW(optimizer_grouped_parameters,\n","                     lr=learning_rate,\n","                     )\n","\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77a8095aea3948b4894ed77df8ed7e9d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=810912.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebc009bb542d42f6aa79157269ba8cfe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82b6a7579d0c42668c339479343f3294","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445032417.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NdMmVLJlG8Ly","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1598049209584,"user_tz":-60,"elapsed":738809,"user":{"displayName":"Ayush Varhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgemDix0i6sVEgvhVaLSsuJCu4bJlsnCE0F9tz9WQ=s64","userId":"15916133275189637335"}},"outputId":"1af51210-0029-4e49-ff9d-3e0b6a86fbea"},"source":["# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","  # Training\n","  model.train()\n","  \n","  # Tracking variables\n","  training_loss = 0\n","  nbatch_training_examples, nbatch_training_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    batch_input_ids, batch_input_mask, batch_labels = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    loss = model(batch_input_ids,  attention_mask=batch_input_mask, labels=batch_labels)\n","\n","    train_loss_set.append(loss[0])    \n","    # # Backward pass\n","    loss[0].backward()\n","    optimizer.step()\n","     \n","    \n","    # Update tracking variables\n","    training_loss =training_loss+ loss[0]\n","    nbatch_training_examples =nbatch_training_examples+ batch_input_ids.size(0)\n","    nbatch_training_steps =nbatch_training_steps+ 1\n","\n","  print(\"Train loss: {}\".format(training_loss/nbatch_training_steps))\n","    \n","    \n","  # Validation\n","  model.eval()\n","\n","  # Tracking variables \n","  evaluation_loss, evaluation_accuracy = 0, 0\n","  nbatch_evaluation_steps, nbatch_evaluation_examples = 0, 0\n","  eval_f1, eval_precision = 0,0\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    batch_input_ids, batch_input_mask, batch_labels = batch\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      logits = model(batch_input_ids,  attention_mask=batch_input_mask)[0]\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = batch_labels.to('cpu').numpy()\n","\n","    tmp_evaluation_accuracy = accuracy_score(np.argmax(logits, axis=1).flatten(), label_ids.flatten()) \n","    eval_f1 += f1_score(np.argmax(logits, axis=1).flatten(), label_ids.flatten(), average='weighted') \n","    eval_precision += precision_score(np.argmax(logits, axis=1).flatten(), label_ids.flatten(), average='weighted')\n","    \n","    evaluation_accuracy = evaluation_accuracy + tmp_evaluation_accuracy\n","    nbatch_evaluation_steps = nbatch_evaluation_steps+1\n","\n","  print(\"Validation Accuracy: {}\".format(evaluation_accuracy/nbatch_evaluation_steps))\n","  print(\"Validation F1 score: {}\".format(eval_f1/nbatch_evaluation_steps))\n","  print(\"Validation precision: {}\".format(eval_precision/nbatch_evaluation_steps))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 1.2544441223144531\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  25%|██▌       | 1/4 [03:04<09:14, 184.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.5857213438735177\n","Validation F1 score: 0.5956372466844462\n","Validation precision: 0.636901913161716\n","Train loss: 0.8986567854881287\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 2/4 [06:09<06:09, 184.69s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.7369688735177865\n","Validation F1 score: 0.7516920024484383\n","Validation precision: 0.8014926042478455\n","Train loss: 0.6020081639289856\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  75%|███████▌  | 3/4 [09:13<03:04, 184.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.7897418478260869\n","Validation F1 score: 0.7972302548203918\n","Validation precision: 0.8228301680538658\n","Train loss: 0.4490740895271301\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 4/4 [12:17<00:00, 184.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.8324790019762847\n","Validation F1 score: 0.841480549347694\n","Validation precision: 0.8742922654635186\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3bMtLZh9HIaz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}